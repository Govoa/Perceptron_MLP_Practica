{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as ker\n",
    "# import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables a definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronas de la capa ocula válidas\n"
     ]
    }
   ],
   "source": [
    "entradas = np.array([[0,0],[0,1],[1,0],[1,1]]) # Las cuatro posibles entradas de XOR\n",
    "esperadas = np.array([[0],[1],[1],[0]]) # Las cuatro posibles salidas de XOR. En este caso es necesario definirlas para para luego meterlas en el modelo MLP\n",
    "nNeuronasCapaOculta = 3 # Tocar\n",
    "Epoch = 1000 # Tocar\n",
    "\n",
    "def validar_neuronas_oculta(M,N,n): # Empleamos esta funcion para validar que las neuronas de la capa oculta cumplen con la regla aprendida en clase\n",
    "    # La regla a validar es (M/2N < n < 2M/N)\n",
    "    # Siendo M: ejemplos de entrenamiento // N: neuronas de entrada // n: neuronas de la capa oculta\n",
    "\n",
    "    if((M/(2*N)) < n and n < ((2*M)/N)):\n",
    "        return print(\"Neuronas de la capa ocula válidas\") # validamos\n",
    "    return print(\"Neuronas de la capa ocula NO válidas\")\n",
    "\n",
    "validar_neuronas_oculta(4,2,nNeuronasCapaOculta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación y ajuste de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 18:32:00.468265: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-08 18:32:00.471726: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# En este caso se nos pide realizar un modelo fully connected y secuencial. La API Keras no proporciona una clase concoida como Sequential()\n",
    "# De esta manera podemos crear un modelo secuencial que automaticamente esta fully connected.\n",
    "# Para crear este modelo tenemos que ir agregando capas, stackeandolas.\n",
    "\n",
    "MLP = ker.Sequential() # Creamos el modelo vacío\n",
    "# Añadimos una capa (tecnicamente dos, la de entrada (con la variable input_dim) y la oculta)\n",
    "MLP.add(ker.layers.Dense(nNeuronasCapaOculta, input_dim = 2, activation='relu'))\n",
    "# Añadimos la capa de salida, con una única neurona. EN este caso el input no hace falta porque ya asume que son las neuronas de capa oculta, ya\n",
    "# que las capas se stackean\n",
    "MLP.add(ker.layers.Dense(1,activation='sigmoid')) \n",
    "\n",
    "# Por último tenemos que configurar el modelo antes de entrenarlo con lo dicho en el enunciado\n",
    "# Optimizador: Adam\n",
    "# Función error: Mean Squared Error\n",
    "# Metricas = Binary accuracy porque nos da el número de precisión de la red\n",
    "MLP.compile(optimizer='adam',loss='mean_squared_error',metrics=[\"binary_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 18:32:01.586723: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Por último entrenamos la red con el epoch (nº iteraciones) y verbose para que nos saque los datos para el estudio\n",
    "output_fit = MLP.fit(entradas,esperadas,epochs=Epoch,verbose = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calidad de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(output_fit.history['accuracy'])\n",
    "plt.plot(output_fit.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(output_fit.history['loss'])\n",
    "plt.plot(output_fit.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ VALORES XOR ================\n",
      "ENTRADA -> [0 0]  EXPECTED -> 0  OBTENIDO -> [0.]\n",
      "ENTRADA -> [0 1]  EXPECTED -> 1  OBTENIDO -> [1.]\n",
      "ENTRADA -> [1 0]  EXPECTED -> 1  OBTENIDO -> [0.]\n",
      "ENTRADA -> [1 1]  EXPECTED -> 0  OBTENIDO -> [0.]\n"
     ]
    }
   ],
   "source": [
    "# Una vez tenemos entrenada la red, probamos todas las entradas y vemos si funciona\n",
    "i = 0\n",
    "resultados = MLP.predict(entradas).round()\n",
    "print(\"================ VALORES XOR ================\")\n",
    "for entrada in entradas:\n",
    "    print(\"ENTRADA ->\", entrada, \" EXPECTED ->\", (entrada[0] ^ entrada[1]) ,\" OBTENIDO ->\", resultados[i])\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f28dc4781dab19edf63b5c71a1687fff9fce01d0e8a3b589ee0bb3a5a37f0a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
